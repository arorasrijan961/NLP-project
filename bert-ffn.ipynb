{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler\n",
    "from torch import nn\n",
    "\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "RANDOM_SEED=30\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if(torch.cuda.is_available()):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "MAX_LEN=256\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are multiple ways to obtain datasets: with/without stopwords, augmented with hateEval/not augmented, and with 0 label samples oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35089, 3)\n",
      "(3966, 3)\n"
     ]
    }
   ],
   "source": [
    "def create_dataframes(stopwords=False, oversampling=0, augmented=False):\n",
    "    if(stopwords and augmented):\n",
    "        df_train=pd.read_csv('train_augmented_with_stopwords.csv')\n",
    "        df_val=pd.read_csv('val_with_stopwords.csv')\n",
    "    elif(stopwords and (not augmented)):\n",
    "        df_train=pd.read_csv('train_new_with_stopwords.csv')\n",
    "        df_val=pd.read_csv('val_with_stopwords.csv')\n",
    "        \n",
    "    elif((not stopwords) and augmented):\n",
    "        df_train=pd.read_csv('train_augmented_without_stopwords.csv')\n",
    "        df_val=pd.read_csv('val_without_stopwords.csv')\n",
    "    \n",
    "    elif((not stopwords) and (not augmented)):\n",
    "        df_train=pd.read_csv('train_new_without_stopwords.csv')\n",
    "        df_val=pd.read_csv('val_without_stopwords.csv')\n",
    "        \n",
    "    df_train_0=df_train.loc[df_train['label']==0]\n",
    "    for i in range(oversampling):\n",
    "        df_train=df_train.append(df_train_0, ignore_index=True)\n",
    "        \n",
    "    return df_train, df_val\n",
    "\n",
    "\n",
    "df_train, df_val=create_dataframes(augmented=True)\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, output_hidden_states=True)\n",
    "\n",
    "class TweetDataset(Dataset):\n",
    "\n",
    "    def __init__(self, tweets, labels, tokenizer, max_len, transform = None):\n",
    "        self.tweets = tweets\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.transform = transform\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.tweets)\n",
    "  \n",
    "    def __getitem__(self, item):\n",
    "        tweet = str(self.tweets[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "        tweet,\n",
    "        add_special_tokens=True,\n",
    "        max_length=self.max_len,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "        truncation = True,\n",
    "        )\n",
    "        sample = {\n",
    "        'text': tweet,\n",
    "        'input_ids': encoding['input_ids'].flatten(),\n",
    "        'attention_mask': encoding['attention_mask'].flatten(),\n",
    "        'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "        if(self.transform):\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "        \n",
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = TweetDataset(\n",
    "    tweets=df['tweet'].to_numpy(),\n",
    "    labels=df['label'].to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "    )\n",
    "\n",
    "    return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    sampler=RandomSampler(ds),\n",
    "    num_workers=8\n",
    "    )\n",
    "    \n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "\n",
    "\n",
    "# only for kaggle submission\n",
    "# class TestDataset(Dataset):\n",
    "\n",
    "#     def __init__(self, tweets, index, tokenizer, max_len, transform = None):\n",
    "#         self.tweets = tweets\n",
    "#         self.index = index\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_len = max_len\n",
    "#         self.transform = transform\n",
    "  \n",
    "#     def __len__(self):\n",
    "#         return len(self.tweets)\n",
    "  \n",
    "#     def __getitem__(self, item):\n",
    "#         tweet = str(self.tweets[item])\n",
    "#         index = self.index[item]\n",
    "#         encoding = self.tokenizer.encode_plus(\n",
    "#         tweet,\n",
    "#         add_special_tokens=True,\n",
    "#         max_length=self.max_len,\n",
    "#         return_token_type_ids=False,\n",
    "#         padding='max_length',\n",
    "#         return_attention_mask=True,\n",
    "#         return_tensors='pt',\n",
    "#         truncation = True,\n",
    "#         )\n",
    "#         sample = {\n",
    "#         'text': tweet,\n",
    "#         'input_ids': encoding['input_ids'].flatten(),\n",
    "#         'attention_mask': encoding['attention_mask'].flatten(),\n",
    "#         'index': index\n",
    "#         }\n",
    "#         if(self.transform):\n",
    "#             sample = self.transform(sample)\n",
    "#         return sample\n",
    "\n",
    "# def create_test_loader(df, tokenizer, max_len, batch_size):\n",
    "#     ds = TestDataset(\n",
    "#     tweets=df['tweet'].to_numpy(),\n",
    "#     index=df['index'].to_numpy(),\n",
    "#     tokenizer=tokenizer,\n",
    "#     max_len=max_len\n",
    "#     )\n",
    "\n",
    "#     return DataLoader(\n",
    "#     ds,\n",
    "#     batch_size=batch_size,\n",
    "#     num_workers=8\n",
    "#     )\n",
    "    \n",
    "# test_data_loader = create_test_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HateSpeechClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes, lm):\n",
    "        super(HateSpeechClassifier, self).__init__()\n",
    "        self.lm = lm\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.out = nn.Sequential(\n",
    "            # nn.Linear(self.lm.config.hidden_size, 512),\n",
    "            # nn.Tanh(),\n",
    "            nn.Linear(self.lm.config.hidden_size, 256), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(256, 32), \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, n_classes),\n",
    "            # nn.Softmax(n_classes),\n",
    "        )\n",
    "  \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        bert_output = self.lm(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "        )\n",
    "        output = self.drop(bert_output[1])\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HateSpeechClassifier(n_classes=3, lm = bert_model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model,\n",
    "    data_loader, \n",
    "    loss_func, \n",
    "    optimizer, \n",
    "    device, \n",
    "    scheduler,\n",
    "    n_examples\n",
    "):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    for d in data_loader:\n",
    "        input_ids = d['input_ids'].to(device)\n",
    "        attention_mask = d['attention_mask'].to(device)\n",
    "        labels = d['label'].to(device)\n",
    "        \n",
    "        output = model(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask\n",
    "        )\n",
    "        \n",
    "        _, prediction = torch.max(output, dim=1)\n",
    "        loss = loss_func(output, labels)\n",
    "        \n",
    "        correct_predictions += torch.sum(prediction == labels)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "\n",
    "def val_epoch(\n",
    "    model,\n",
    "    data_loader, \n",
    "    device,\n",
    "):\n",
    "    p=[]\n",
    "    y_true=[]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            output = model(\n",
    "                input_ids=d['input_ids'].to(device),\n",
    "                attention_mask=d['attention_mask'].to(device),\n",
    "            )\n",
    "            y_true+=(d['label'].tolist())\n",
    "            _, prediction=torch.max(output, dim=1)\n",
    "            p+=prediction.tolist()\n",
    "        \n",
    "        \n",
    "    prediction=np.array(p)\n",
    "    y_true=np.array(y_true)\n",
    "    \n",
    "    accuracy=accuracy_score(y_true, prediction)\n",
    "    macro_f1_score=f1_score(y_true, prediction, average='macro')\n",
    "    conf_mat=confusion_matrix(y_true, prediction)\n",
    "    \n",
    "    return accuracy, macro_f1_score, conf_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, eps=1e-9)\n",
    "total_steps = len(train_data_loader)*EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-61ff03f94828>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f93aae5284f2>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, loss_func, optimizer, device, scheduler, n_examples)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcorrect_predictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_epoch=0\n",
    "best_score=0\n",
    "for i in range(EPOCHS):\n",
    "    train_accuracy, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        loss_func,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler, \n",
    "        len(df_train)\n",
    "    )\n",
    "    print(\"Epoch: \", i)\n",
    "    # print(\"Accuracy: \"+ str(train_accuracy.item()) + \"\\tLoss: \"+str(train_loss))\n",
    "    \n",
    "    val_accuracy, val_f1_score, conf_mat=val_epoch(model=model, data_loader=val_data_loader, device=device)\n",
    "    print(\"Val accuracy: \"+str(val_accuracy)+\"\\tVal f1_score: \"+str(val_f1_score))\n",
    "    if(val_f1_score>best_score):\n",
    "        best_epoch=i\n",
    "        best_score=val_f1_score\n",
    "        best_conf_mat=conf_mat\n",
    "        best_accuracy=val_accuracy\n",
    "        torch.save(model.state_dict(), './bert-fnn-oversampled1-1.pt')\n",
    "    \n",
    "print(\"Ideal number of epochs: \", best_epoch+1)\n",
    "best_epoch+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7037"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3\n",
      "Accuracy:  0.9041855774079677\n",
      "F1-score:  0.7546080617778644\n",
      "Confusion matrix\n",
      " [[  98  130   24]\n",
      " [  71 2914   95]\n",
      " [  10   50  574]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Epoch: \", best_epoch)\n",
    "print(\"Accuracy: \", best_accuracy)\n",
    "print('F1-score: ', best_score)\n",
    "print(\"Confusion matrix\\n\", best_conf_mat)\n",
    "sns.heatmap(best_conf_mat, annot=True, cmap='crest')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40c8aee14bfcd74aa3931897f14b05b05ebb9b88f6cef370cd02f0c54cc83820"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
