{"cells":[{"cell_type":"code","execution_count":62,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11280,"status":"ok","timestamp":1670162737973,"user":{"displayName":"Utkarsh Pal","userId":"04533577990891075513"},"user_tz":-330},"id":"VbaBAGw5tJel","outputId":"da2f64d6-ab3e-446b-eec9-6e5487d6d1ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003c0.14,\u003e=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.10.0-\u003etransformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging\u003e=20.0-\u003etransformers) (3.0.9)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers) (2022.9.24)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: SentencePiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n"]}],"source":["!pip install transformers\n","!pip install SentencePiece"]},{"cell_type":"code","execution_count":63,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1670162737976,"user":{"displayName":"Utkarsh Pal","userId":"04533577990891075513"},"user_tz":-330},"id":"DY8Wqrmgp-iL"},"outputs":[],"source":["import gc\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler\n","from torch import nn\n","\n","import transformers\n","from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup, ElectraTokenizer, ElectraModel\n","\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n","from sklearn.metrics import accuracy_score, f1_score , confusion_matrix\n","\n","RANDOM_SEED=30\n","np.random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","if(torch.cuda.is_available()):\n","    torch.cuda.empty_cache()\n","    gc.collect()\n"]},{"cell_type":"code","execution_count":64,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1670162737976,"user":{"displayName":"Utkarsh Pal","userId":"04533577990891075513"},"user_tz":-330},"id":"PxdUDOXmp-iO"},"outputs":[],"source":["BATCH_SIZE = 16\n","MAX_LEN=256\n","PRE_TRAINED_MODEL_NAME = 'google/electra-small-generator'"]},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4153,"status":"ok","timestamp":1670162742117,"user":{"displayName":"Utkarsh Pal","userId":"04533577990891075513"},"user_tz":-330},"id":"Qv_IYPQEtZ1u","outputId":"38388094-e1ee-4522-e8d4-3d7964cb7a2c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":66,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1670162742117,"user":{"displayName":"Utkarsh Pal","userId":"04533577990891075513"},"user_tz":-330},"id":"ql58wcAjta2Q"},"outputs":[],"source":["path = 'drive/MyDrive/report_material/'"]},{"cell_type":"code","execution_count":67,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1670162742118,"user":{"displayName":"Utkarsh Pal","userId":"04533577990891075513"},"user_tz":-330},"id":"i0JmcbUILvv-"},"outputs":[],"source":["df_test = pd.read_csv('drive/MyDrive/NLP_Project/test_without_stopwords.csv')"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1670162742118,"user":{"displayName":"Utkarsh Pal","userId":"04533577990891075513"},"user_tz":-330},"id":"CECDA3Hcp-iP","outputId":"ab152fd1-3bf2-41e4-8910-b59a37129499"},"outputs":[{"name":"stdout","output_type":"stream","text":["(17630, 3)\n","(3966, 3)\n","Index(['label', 'tweet', 'index'], dtype='object')\n","1    12318\n","2     2657\n","0     2655\n","Name: label, dtype: int64\n","1    3080\n","2     634\n","0     252\n","Name: label, dtype: int64\n"]}],"source":["def create_dataframes(stopwords=False, oversampling=0, augmented=False):\n","    if(stopwords and augmented):\n","        df_train=pd.read_csv(path+'train_augmented_with_stopwords.csv')\n","        df_val=pd.read_csv(path+'val_with_stopwords.csv')\n","    elif(stopwords and (not augmented)):\n","        df_train=pd.read_csv(path+'train_new_with_stopwords.csv')\n","        df_val=pd.read_csv(path+'val_with_stopwords.csv')\n","        \n","    elif((not stopwords) and augmented):\n","        df_train=pd.read_csv(path+'train_augmented_without_stopwords.csv')\n","        df_val=pd.read_csv(path+'val_without_stopwords.csv')\n","    \n","    elif((not stopwords) and (not augmented)):\n","        df_train=pd.read_csv(path+'train_new_without_stopwords.csv')\n","        df_val=pd.read_csv(path+'val_without_stopwords.csv')\n","        \n","    df_train_0=df_train.loc[df_train['label']==0]\n","    for i in range(oversampling+1):\n","        df_train=df_train.append(df_train_0, ignore_index=True)\n","        \n","    return df_train, df_val\n","\n","\n","df_train, df_val=create_dataframes(oversampling =1)\n","print(df_train.shape)\n","print(df_val.shape)\n","print(df_train.columns)\n","print(df_train['label'].value_counts())\n","print(df_val['label'].value_counts())\n"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":804,"status":"ok","timestamp":1670162742914,"user":{"displayName":"Utkarsh Pal","userId":"04533577990891075513"},"user_tz":-330},"id":"JrJ0PR0jp-iQ","outputId":"478f09e1-d7c7-4606-de77-47b16daeb501"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at google/electra-small-generator were not used when initializing ElectraModel: ['generator_lm_head.bias', 'generator_predictions.dense.bias', 'generator_predictions.LayerNorm.weight', 'generator_lm_head.weight', 'generator_predictions.dense.weight', 'generator_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["tokenizer = ElectraTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n","bert_model = ElectraModel.from_pretrained(PRE_TRAINED_MODEL_NAME, output_hidden_states=True)"]},{"cell_type":"code","execution_count":70,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1670162742914,"user":{"displayName":"Utkarsh Pal","userId":"04533577990891075513"},"user_tz":-330},"id":"jVe3YxZcp-iQ"},"outputs":[],"source":["class TweetDataset(Dataset):\n","\n","    def __init__(self, tweets, labels, tokenizer, max_len, transform = None):\n","        self.tweets = tweets\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        self.transform = transform\n","  \n","    def __len__(self):\n","        return len(self.tweets)\n","  \n","    def __getitem__(self, item):\n","        tweet = str(self.tweets[item])\n","        label = self.labels[item]\n","\n","        encoding = self.tokenizer.encode_plus(\n","        tweet,\n","        add_special_tokens=True,\n","        max_length=self.max_len,\n","        return_token_type_ids=False,\n","        padding='max_length',\n","        return_attention_mask=True,\n","        return_tensors='pt',\n","        truncation = True,\n","        )\n","        sample = {\n","        'text': tweet,\n","        'input_ids': encoding['input_ids'].flatten(),\n","        'attention_mask': encoding['attention_mask'].flatten(),\n","        'label': torch.tensor(label, dtype=torch.long)\n","        }\n","        if(self.transform):\n","            sample = self.transform(sample)\n","        return sample\n","        \n","def create_data_loader(df, tokenizer, max_len, batch_size):\n","    ds = TweetDataset(\n","    tweets=df['tweet'].to_numpy(),\n","    labels=df['label'].to_numpy(),\n","    tokenizer=tokenizer,\n","    max_len=max_len\n","    )\n","\n","    return DataLoader(\n","    ds,\n","    batch_size=batch_size,\n","    sampler=RandomSampler(ds),\n","    num_workers=8\n","    )\n","    \n","\n","train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n","val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n","\n","\n","class TestDataset(Dataset):\n","\n","    def __init__(self, tweets, index, tokenizer, max_len, transform = None):\n","        self.tweets = tweets\n","        self.index = index\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        self.transform = transform\n","  \n","    def __len__(self):\n","        return len(self.tweets)\n","  \n","    def __getitem__(self, item):\n","        tweet = str(self.tweets[item])\n","        index = self.index[item]\n","        encoding = self.tokenizer.encode_plus(\n","        tweet,\n","        add_special_tokens=True,\n","        max_length=self.max_len,\n","        return_token_type_ids=False,\n","        padding='max_length',\n","        return_attention_mask=True,\n","        return_tensors='pt',\n","        truncation = True,\n","        )\n","        sample = {\n","        'text': tweet,\n","        'input_ids': encoding['input_ids'].flatten(),\n","        'attention_mask': encoding['attention_mask'].flatten(),\n","        'index': index\n","        }\n","        if(self.transform):\n","            sample = self.transform(sample)\n","        return sample\n","\n","def create_test_loader(df, tokenizer, max_len, batch_size):\n","    ds = TestDataset(\n","    tweets=df['tweet'].to_numpy(),\n","    index=df['index'].to_numpy(),\n","    tokenizer=tokenizer,\n","    max_len=max_len\n","    )\n","\n","    return DataLoader(\n","    ds,\n","    batch_size=batch_size,\n","    num_workers=8\n","    )\n","    \n","train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n","val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n","\n","test_data_loader = create_test_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n","\n","# data=next(iter(train_data_loader))"]},{"cell_type":"code","execution_count":71,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1670162742914,"user":{"displayName":"Utkarsh Pal","userId":"04533577990891075513"},"user_tz":-330},"id":"RMEZE8Nzp-iR"},"outputs":[],"source":["class HateSpeechClassifier(nn.Module):\n","\n","    def __init__(self, n_classes, lm):\n","        super(HateSpeechClassifier, self).__init__()\n","        self.lm = lm\n","        self.drop = nn.Dropout(p=0.2)\n","        self.out = nn.Sequential(\n","            # nn.Linear(self.lm.config.hidden_size, 512),\n","            # nn.Tanh(),\n","            nn.Linear(self.lm.config.hidden_size, 256), \n","            nn.Tanh(), \n","            nn.Linear(256, 64), \n","            nn.Tanh(),\n","            nn.Linear(64, n_classes),\n","            # nn.Softmax(n_classes),\n","        )\n","  \n","    def forward(self, input_ids, attention_mask):\n","        bert_output = self.lm(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask\n","        )\n","        last_hidden_state = bert_output[0]\n","        mean_last_hidden_state = torch.mean(last_hidden_state, 1)\n","        # output = self.drop(bert_output[1])\n","        return self.out(mean_last_hidden_state)"]},{"cell_type":"code","execution_count":72,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1670162742915,"user":{"displayName":"Utkarsh Pal","userId":"04533577990891075513"},"user_tz":-330},"id":"m7zV1h0jp-iR"},"outputs":[],"source":["# sample_dataset=TweetDataset(df_train['tweet'].to_numpy(), df_train['label'].to_numpy(), tokenizer, 3)\n","# sample=sample_dataset.__getitem__(0)\n","# print(sample)\n","# input_ids=sample['input_ids'].to(device)\n","# attention_mask=sample['attention_mask'].to(device)\n","# output=bert_model(input_ids=input_ids, attention_mask=attention_mask)\n","# print(output)"]},{"cell_type":"code","execution_count":73,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1670162742915,"user":{"displayName":"Utkarsh Pal","userId":"04533577990891075513"},"user_tz":-330},"id":"bOOUN1jsp-iS"},"outputs":[],"source":["model = HateSpeechClassifier(n_classes=3, lm = bert_model)\n","model = model.to(device)"]},{"cell_type":"code","execution_count":74,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1670162742915,"user":{"displayName":"Utkarsh Pal","userId":"04533577990891075513"},"user_tz":-330},"id":"G-p3p4rzt9yY","outputId":"0b2d5b95-e43f-45a3-e4cd-c9532dc26ed8"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n"]}],"source":["for param in bert_model.base_model.parameters():\n","    print(param.requires_grad)"]},{"cell_type":"code","execution_count":75,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1670162742915,"user":{"displayName":"Utkarsh Pal","userId":"04533577990891075513"},"user_tz":-330},"id":"6Pjk7xugp-iS"},"outputs":[],"source":["EPOCHS = 10\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=5e-6, eps=1e-8)\n","total_steps = len(train_data_loader)*EPOCHS\n","\n","\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps=0, \n","    num_training_steps=total_steps\n",")\n","\n","loss_func = nn.CrossEntropyLoss().to(device)"]},{"cell_type":"code","execution_count":76,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1670162742916,"user":{"displayName":"Utkarsh Pal","userId":"04533577990891075513"},"user_tz":-330},"id":"lwHU8uHAp-iT"},"outputs":[],"source":["def train_epoch(\n","    model,\n","    data_loader, \n","    loss_func, \n","    optimizer, \n","    device, \n","    scheduler,\n","    n_examples\n","):\n","    model = model.train()\n","    losses = []\n","    correct_predictions = 0\n","    for d in data_loader:\n","        input_ids = d['input_ids'].to(device)\n","        attention_mask = d['attention_mask'].to(device)\n","        labels = d['label'].to(device)\n","        \n","        output = model(\n","            input_ids = input_ids,\n","            attention_mask = attention_mask\n","        )\n","        \n","        _, prediction = torch.max(output, dim=1)\n","        loss = loss_func(output, labels)\n","        \n","        correct_predictions += torch.sum(prediction == labels)\n","        losses.append(loss.item())\n","        \n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","        \n","    return correct_predictions.double() / n_examples, np.mean(losses)\n","\n","\n","def val_epoch(\n","    model,\n","    data_loader, \n","    device,\n","):\n","    p=[]\n","    y_true=[]\n","    model.eval()\n","    with torch.no_grad():\n","        for d in data_loader:\n","            output = model(\n","                input_ids=d['input_ids'].to(device),\n","                attention_mask=d['attention_mask'].to(device),\n","            )\n","            y_true+=(d['label'].tolist())\n","            _, prediction=torch.max(output, dim=1)\n","            p+=prediction.tolist()\n","        \n","        \n","    prediction=np.array(p)\n","    y_true=np.array(y_true)\n","    \n","    accuracy=accuracy_score(y_true, prediction)\n","    macro_f1_score=f1_score(y_true, prediction, average='macro')\n","    confusion_matrix_calc = confusion_matrix(y_true, prediction)\n","    \n","    return accuracy, macro_f1_score , confusion_matrix_calc\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"IqDfO1Tip-iT"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch:  0\n"]}],"source":["best_epoch=0\n","best_score=0\n","best_confusion_matrix = []\n","best_accuracy=0\n","for i in range(EPOCHS):\n","    print(\"Epoch: \", i)\n","    train_accuracy, train_loss = train_epoch(\n","        model,\n","        train_data_loader,\n","        loss_func,\n","        optimizer,\n","        device,\n","        scheduler, \n","        len(df_train)\n","    )\n","    # print(\"Accuracy: \"+ str(train_accuracy.item()) + \"\\tLoss: \"+str(train_loss))\n","    \n","    val_accuracy, val_f1_score , val_confusionmatrix =val_epoch(model=model, data_loader=val_data_loader, device=device)\n","    print(\"Val accuracy: \"+str(val_accuracy)+\"\\tVal f1_score: \"+str(val_f1_score))\n","    print(\"Confsuion Matrix\" , val_confusionmatrix)\n","    if(val_f1_score\u003ebest_score):\n","        best_epoch=i\n","        best_score=val_f1_score\n","        best_accuracy=val_accuracy\n","        best_confusion_matrix = val_confusionmatrix\n","        torch.save(model.state_dict(), './electra-oversampled.pt')\n","    \n","print(\"Ideal number of epochs: \", best_epoch+1)\n","print(\"BEST Confsuion Matrix\" , best_confusion_matrix)\n","\n","best_epoch+=1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mx1vEn7TTDoq"},"outputs":[],"source":["import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MTcAWeWSTIxi"},"outputs":[],"source":["print(\"Ideal number of epochs: \", best_epoch)\n","print(\"Best Score \" , best_score)\n","print(\"Best accuracy \" , best_accuracy )\n","print(\"Best Confsuion Matrix : \\n \" , best_confusion_matrix)\n","sns.heatmap(best_confusion_matrix, annot=True, cmap='crest')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PiPNLHYQuR8h"},"outputs":[],"source":["model = HateSpeechClassifier(n_classes=3, lm = bert_model)\n","model.load_state_dict(torch.load('./electra-oversampled.pt'))\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O2bk5IOVuR5Y"},"outputs":[],"source":["p=[]\n","index_list=[]\n","model.eval()\n","for d in test_data_loader:\n","    \n","    output = model(\n","        input_ids=d['input_ids'].to(device),\n","        attention_mask=d['attention_mask'].to(device),\n","    )\n","    index_list+=(d['index'].tolist())\n","    _, prediction=torch.max(output, dim=1)\n","    \n","    p+=prediction.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QVDF3TeQuR0G"},"outputs":[],"source":["output_df=pd.DataFrame(columns=['label', 'id'])\n","output_df['label']=p\n","output_df['id']=index_list\n","\n","output_df.sort_values(by=['id'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dB32QGnvucFG"},"outputs":[],"source":["output_df.to_csv(path+\"outputs-electra.csv\", index=False, encoding='utf-8-sig')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rEWkE2c9p-iT"},"outputs":[],"source":["torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qztns75np-iU"},"outputs":[],"source":["bert_model = ElectraModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n","model = HateSpeechClassifier(n_classes=3, lm = bert_model)\n","model = model.to(device)\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n","total_steps = len(train_data_loader)*3\n","\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps=0, \n","    num_training_steps=total_steps\n",")\n","\n","loss_func = nn.CrossEntropyLoss().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MyM0SeTrp-iU"},"outputs":[],"source":["for i in range(4):\n","    train_accuracy, train_loss = train_epoch(\n","        model,\n","        train_data_loader,\n","        loss_func,\n","        optimizer,\n","        device,\n","        scheduler, \n","        len(df_train)\n","    )\n","    filename='./bert-augmented-fnn-2-'+str(i)+'.pt'\n","    torch.save(model.state_dict(), filename)\n","    print(i)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ktbQWe81p-iU"},"outputs":[],"source":["for i in range(4):\n","    filename='./bert-augmented-fnn-2-'+str(i)\n","    temp = HateSpeechClassifier(n_classes=3, lm = bert_model)\n","    temp.load_state_dict(torch.load(filename+'.pt'))\n","    temp = temp.to(device)\n","    \n","    p=[]\n","    index_list=[]\n","    temp.eval()\n","    for d in test_data_loader:\n","        \n","        output = temp(\n","            input_ids=d['input_ids'].to(device),\n","            attention_mask=d['attention_mask'].to(device),\n","        )\n","        index_list+=(d['index'].tolist())\n","        _, prediction=torch.max(output, dim=1)\n","        \n","        p+=prediction.tolist()\n","    output_df=pd.DataFrame(columns=['label', 'id'])\n","    output_df['label']=p\n","    output_df['id']=index_list\n","\n","    output_df.sort_values(by=['id'])\n","    \n","    output_df.to_csv(filename+'.csv', index=False)\n","    print(i)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gmmpLPVTp-iU"},"outputs":[],"source":["output_df=pd.DataFrame(columns=['label', 'id'])\n","output_df['label']=p\n","output_df['id']=index_list\n","\n","output_df.sort_values(by=['id'])"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPYCuLl7FyvMeLKGdQgLCW5","name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}